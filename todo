psana2 analysis affected by db?
* mikhail scons, saxs/waxs parallelizable mpeg, kcu-xpm in fee, update camlink devices, xpm loopback failures, outage message, revisit hsd buffer size (131kB), 13us fim difference, rix hsd2/3, kirian psana1 docs, atm ok with lcls2 event codes, handling on-call 0x8623, grafana-to-epics, intg_det slowupdate/l1 prio, cassettes, tmoc00221 run 50 scan hang, lcls2 damage stats (and event counters?), cxix1000021:run5 det.image, acr feedback, txi kpp (grp7 grafana), cmp041, 156 subnet jira, matt tdet firmware everywhere, more timing cables emu

power outage projects:
- slurm (caf, ric)
- configdb old-object removal (caf)
- ami filter box (dan)
- jump to timestamp (mona)
- papers (everyone)
- grafana-to-epics (ric)
- psana1 build/test in s3df (mikhail)
- hdf5 jupyter in s3df
- accelerator patterns for rix and opal dropped shots (matt)
- keras for juhao (riccardo)
- poor psana1 jungfrau-calib scaling
- fifo-reset fix for bucket-hopping timestamps (matt)
- vds with missing h5 data in some files (riccardo, mona, anyone)
- h5 timestamp sort with dask (mona)
- s3df hiprioq proposal for 1000's of cores (yee with others)
- lcls2 daq after-the-fact aliases
- more data reduction libsz testing
- check for differing types in smd.sum
- separate daq/ana envs
- psana2 detnames with wrong syntax produces incorrect output
  (e.g. the ";" here: "detnames exp=rixc00121;run=81") (mikhail, mona)
- better error when running psana with small data but not setting PS_SRV_NODES  and when number of cores are incorrect (mona, mikhail)
- ami python editor returning array with one element into ScalarPlot generates no visible error (but see error in logs)
- lcls2 inline and web documentation? (mikhail)
- only 4-bits for xpm number in remote link id (matt)
- not all errors show up in ami gui, e.g. missing attribute error (ddamiani)
- ami 3D angular integration (mikhail)
- "exposure time" integrating detector (mona)
- SZ-gpu (stefano)
- simple mpeg-style saxs/waxs (stefano)
- psana test to verify that all detector interfaces follow the rules
- swmr with small h5
- support damage in psana2 (mona)
- gpu detector corrections
- syslog print throttling (caf)

dan projects:
- delay line detector
- alice green ami graph for lcls1
- vincent filter box
- jungfrau 16M
- mec varex, xpp orca quest? depending on priorities
- clean up ami tmo/rix errors
- in psana SRV callback only persist some fields to h5?

caf projects:
- configdb remove/hide unused detectors
- syslog print throttling (caf)

matt projects:
switch to official BLD data-description server
schedule acr/rix accelerator burst-pattern mtg
hsd repair
tmo-to-acr feedback without gateways (bld or epics or both)
robustness of timing links (install new tdet firmware everywhere?)

ric projects:
- psana grafana
- libsz to roi switch (and easily change roi config params)
- epixhremu to 20 nodes
- multicamlink drp

riccardo proj:
- xpm loopback failure
- epixuhr
- finishing uproot
- juhao work (keras)
- reproduce timing problems in fee teststand

mona proj:
- more timing fibers for ric epixhr emulation
- better error messages
- vds with missing h5 data in some files?
- high rate encoder
- destination callback (conflicts with integrating detector?). work with silke,andy@txi
- h5 time sort

s3df issues:
- cong folding jobs
- default jupyter to batch and add note
- adding users to slurm accounts
- how does slurm gather cores for mpi?
- hierarchy of shares (waiting on procurements, this week): will set to number of "purchased" cores: cryoem: 33, fermi 33, lcls 111, rubin 1?, ad 13, simes 1?
- "perazzo" sharing (needs a scalable way of calling the "delta" function)
  o delta-function (allocated vs. used) takes a long time to compute: can create a denial-of-service of slurm since it's slow
  o "forcing" people into preemptable when they exceed their allocation
- jupyter automatic queue selection
- weka: read-while-write (permissions fixed with 4.2.4)
- silke: coordinator roles deprecated for job kill, since it's global (rubin, lcls...)

tmo detectors:

Detectors to be ready in June: 2X FIMs (2 on KB1), ATM opal&piranha for IP1, FZP opal&piranha, HSDs, BLD, Laser wav8, IM5K4 

Detectors to be added by the end of calendar year 2023: two more FIMs on KB2 and IM6K4, ATM opal&piranha for IP2, another Laser wav8 for IP2

detector requests priority update:
meeting with sebastien/james/georgi on nov. 20, 2023
- (mostly done) rixccd
- superconducting phase-cavity (close) and ebeam BLD for lcls2
- small txi epixHR (beginning of 2025)
- rix high-rate mono-encoder
- mfx jungfrau16M (a year)
- tmo tixel (running standalone in february?)
  - magnetic bottle expts could use existing detector
  - would be nice to replace a dream delay-line-detector
    with tixel? need a larger one. not obligated to users
    higher priority than big txi epixHR
  - could replace k-microscope delay-line detector
- rix axis sxr-60 camera (chemrix spectrometer)
  - smaller pixel than epix
  - can't use andor: flange-mount makes grazing-incidence difficult
  - could happen before "the shutdown" (july 2025)
  - highest priority for new instrument for rixs experiments
  - plan is to implement as an IOC (who? dan? if tid could do it that would be great)
- big txi epixHR (big one delayed until aug 2025)
- rix epixM (depends on approved experiments)
- rix k-microscope delay-line-detector (depends on approved experiments)
  o should we use the dream dld instead?
  o communicate with Bob Schoenlein
- epixUHR (testing and in XPP, production not until late 2026)
- ued andor ixon (the camera used in the old daq? but maybe not)
  - maybe an IOC because of long integration times
  - might not be too bad if it's an andor
  - get more information
- opal replacement?
  - imperx? AD supports IOC with pgp-camlink. not super-fast (60Hz-100Hz)
  - maybe not necessary since gige can be timestamped at 100Hz? needs testing
    can talk to dougie about some data taken with high rate exit-slit manta
    (progress from Dan and MikeB)
- (previously approved for "standalone running") rix timepix
  - tixel does same sort of thing
  - done by anton
  - no definitive plans
  - josh turner is supposed to work with anton
  - successor to epixM to get to high rates (or tixel)
- (previously "unapproved") mec varex (a user group is bringing one to MEC)
- (previously "unapproved") xpp orca

- (det) rixccd archon (installed in hutch march 2023, beam oct 2023?)
- superconducting BLD (fall 2022)
- (tid) high-rate mono-encoder
  o interpolated absolute encoder (march 2023)
  o high rate relative encoder (december 2023)
- (unapproved) ikon (for SVLS, kristjan et al., early 2023, perhaps princeton mid-late 2023?)
- (tid, det?) k-microscope dld (test early summer 2022, production in early 2023?, beam summer 2023)
- (det) uxi needs more work from dan (lcls1)
- (standalone approved) (tid, det) tixel (tmo standalone rogue tmo, dec. 2022?, daq integration if looks good)
  o bojan in TID is doing the work
- (tid, det) epixM (lorenzo, integration prototype (no asic, no emulation) from tid beginning of end of august 2023 with asics? 2 320kpx, 5kHz),
  - no fixed gain mode, only one autorange mode AHL, some gain ambiguity that needs to be resolved
  - integrate in november 2022.  full cam in june 2023.
  - MTP24 broken out to 3 MTP8 fiber 6.4GB/s
  - 384*192*2 per camera (737MB/s per camera @5kHz)
- (tid,det) epixHR (prototype quad in march, start work sept 2022, 2Mpx, 5kHz, summer 2023) single MTP24 broken out to 3 MTP8 fibers: prototype in august 2022, beam in sept 2022 (and dec 22). quad in November 2022.  full cam in march 2023.  full 2M det commissioning june 2023.  quad is different than single.
  - 5 to 10 fibers pairs needs to be converted (use local xpm to generate
    multimode).  maybe 12 if edge-ml stuff.
  - 2 small epixHR's (140kpx?) single MTP12
- tmo cookiebox (early 2024): guarantee 8 channels, hope for 16
- mfx jungfrau 16M
- (will approve) (tid) opal replacement (s991? photometrics kinetix? giacomo thinks perhaps alvium?) https://www.alliedvision.com/en/products/alvium-configurator/alvium-1800-u/240/#_configurator
- (approved for standalone) (tid,det) timepix for rix: standalone mode in July 2022 (256x256 px,
  o get start-time and time-over-threshold, ~2kHz, could be faster)
  o working with anton tremsin at berkeley
- (unapproved) (det) varex xrd 4343 cameras for mec? (offered assistance, lcls1, needed april/may 2023)
- (unapproved) orca quest hamamatsu cxp camera? (lcls1, xpp? matt seaberg takahiro)
  https://www.hamamatsu.com/eu/en/product/cameras/qcmos-cameras/C15550-20UP.html
- (tid, det) small epixUHR (200x200): (emulator available end of feb. 2023) beam-test with daq april 2023 (35kHz).
  not identical to epixHR.
  - daq integration with firmware emulator in jan 2023?  prototype 1 asic in april 2023? beam time soon after
- andor iXon for UED, alex reid (flexible, June/July 2023?)
- axis-sxr-60-std 36MPx 26Hz camera request from Kristjan in RIX
  https://www.axis-photon.com/streak-camera/axis-sxr-60-36mpix-soft-x-ray-scmos-camera/

* grafana to epics alarm handler
* after-the-fact lcls2 daq alias in database (both configdb and detnames)
* share simple python code between ami2/psana1/psana2 (amityping, psmon, "HPolar")
* datasource kwarg to suppress fetching of calib constants for mikhail's mask editor (mona)
* split daq/ana conda envs (valerio)
* hsd raw/fex counters so james can alarm on low raw rates (weaver)
* calibconst for lcls1 for ami2 (e.g. jungfrau)
* saxs/waxs data reduction (stefano)
* uniform (epics?) interface to detector config registers for config scans
* fluctuation saxs/waxs data reduction (stefano)
* manage running-condition dependent calibration constants (e.g. rate dependent) (tweak serial id?) (mikhail)
* ami roiarch with 3D (mikhail)
* improve destination callback (mona)
* event counts in logbook for phil
* monitoring new serial numbers for LCLS2 (mikhail)
* release DMA buffers earlier? currently released at same time as pebble (ric)
* running daq with missing (high-rate?) bld (ric claus)
* check for differing types in smd.sum (gives "ndarray not contiguous" err) (mona)
* separate (decouple) daq/ana envs (valerio)
* detnames with wrong syntax produces incorrect output
  (e.g. the ";" here: "detnames exp=rixc00121;run=81") (mikhail, mona)
* running daq with damaging pvadet (ric claus)
* fix daq timeout behavior where we sometimes get damage from many nodes  (ric claus)
* converting grafana values into epics alarms
* configuration management/control for calibration/fexA/fexB
* psana conflict between normalized integrating detectors and cube with destination callback? perhaps not a problem since integrating detector requires stable pump-probe time
* sphinx-like (read-the-docs?, makedocs, github?, confluence) auto-generated documentation (zach, ken, tom caswell) (mikhail)
* eliminate psana1 calibdir in favor of database (mikhail)
* eliminate intermediate "panel" files on disk and put in database (for epix10k/jungfrau) (mikhail)
* better error when running psana with small data but not setting PS_SRV_NODES  and when number of cores are incorrect (mona, mikhail)
* didn't get obvious error when writing to unwriteable wave8 pv register (MasterEnable) (riccardo, mona, ric)
* event counts in elog for phil. jira ecs-3843 (chris ford, mikhail)
* calibration constant provenance (mikhail)
* resurrect psana1 unit tests ("scons test") (mikhail)
* ami python editor returning array with one element into ScalarPlot generates no visible error (but see error in logs)
* when rix piranha had small number of dma buffers (like opal) we often, but not always, got 100% deadtime and BEB timeouts.  feels like buffers not configurerd correctly when deadtime happens (ric, matt, mona, riccardo)
* force inclusion of all necessary TREX data for xtcav
* utility to put lcls2 h5 files in time-order (mona? mikhail? caf? riccardo?)
* understand/fix "384" intermittent libfabric ib completion queue issue (ric) (currently "fixed" by running eblf_pingpong)
* only 4 bits for xpm number in xpm remote link id (matt)
* support libfabric newer "tcp" provider (old one was "sockets") (ric)
* more hsd's for simultaneous cookiebox/dream running (14+16 channels)
  but maybe not more hsd's if tixel works (weaver)
* not all errors show up in ami gui, e.g. missing attribute error (ddamiani)
* andor pedestal subtraction (mikhail)
* managing sharing: readout groups, drp nodes, cnf files, bos connections
 - make drp nodes more uniform?
* mask editor (mikhail)
* when detector list is long in control-gui, can't hit "apply" button  (mikhail)
* when running ami in daq detector list is intermittently not updated (ddamiani)
* have daq bluesky scan scripts default to "scan" as scan detector name to avoid psana crash (caf)
* ability for select-gui to allow teb's to be deselected (down to 1) (mikhail)
* epix100/epixhr deadtime not working (10Hz with epix100)
* ami 3D angular integration (mikhail)
* per stream and per run event/dmg counts (caf)
* better management of drp .service files (shared drive, puppet, kubernetes?)
** integrating detector "exposure time" psana param (mona)
* configure andor with configdb?
* silver behenate fitting (including z-stagger) for panel positions (mikhail)
** benchmark SZ and other reduction for real expt data (mikhail)
  - can SZ handle gain-range detectors?
* make it harder to leave out timing system
* algorithm for non-quantized det-image charge sharing (mikhail)
* raise exception instead of crashing when idx/smd files are missing in psana1
* broadcasting non-epics slowupdate data (e.g. ttool bkdg)
* control_gui not showing up on right screen in tmo (ami, procstat do) (mikhail)
* move encoder to tcp (caf)
* crystfel to psana geom (mikhail)
* ami mypy daemon is long-lived: can cross release boundaries
* configdb management for changing fex/teb decisions
* timetool slowupdate background handling in psana (mona)
* procmgr performance with hundreds of nodes (caf)
* explore object stores for psana like ceph (mona)
* select daq meb monitoring destination for particular events (ric)
* avoid missing 1 second of epicsarch data at beginning of run
* small daq teststand for automated continuous-integration tests?
* multisegment epicsinfo in pvadetector
* ami controlling DRP general ROI with masks via configdb? (mikhail)
* psmon only update one of multiplot (ddamiani)
* psana test to verify that all detector interfaces follow the rules
* psmon XYPlot format list of one item breaks multiple lines silently (ddamiani)
* more psmon examples for andy (ddamiani)
* off-by-one enabling automation (stoppers)
* xface for ami controlling detector params
* web display of ami plots
* mhz bld (matt)
* bld data structure populated automatically from epics
* automatically push releases for lcls1/lcls2 to nersc/sdf/other
* makepeds/calibrun regression tests and simplification or freeze? (mikhail)
* opals for different daq's on same machine (larry+pcds)
* fix psana1 test release LD_PRELOAD hack caused by removal of
  ' -Wl,--copy-dt-needed-entries -Wl,--enable-new-dtags'
  in SConsTools/psdm_cplusplus.py for gcc48.
* psana dbase access for live mode list of files
* handle bad external timing better? (matt)
* generic detector calibration constants (e.g. manta)
* teststand: kcu's to acc nodes (01,02,05,06), bring back ffb, fix ib manager and moving it to switch
* make swmr work with small-h5
** for phil: configdb_readxtc and compare configs (ro, caf)
* lcls2 common-mode for panels in different gain ranges (mikhail)
* address psana/daq prometheus issues described on confluence (mona/ric)
* managing prometheus files in promdir
* put procstat in prometheus (or hard to duplicate all functionality?)
* how to deal with pickle in the calibdb? (mikhail)
* epicsarch support for strings (ric says it's hard)
* support damage in psana, including counting (mona)
* protect against use of keywords as epics aliases, consider using namespacing. write a sanitizer for epicsarch files (use "import keywords"?)
* send clearreadout to pvadetectors
* eliminate opal lcls1->lcls2 timing toggling (julian, matt)
* multiseg epics (kwargs or collection segids?) (mona)
* jungfrau/epix dark shot pedestals
* psana1: implement idx using smd
* correct setting for hyperthreading? (ric says important for MHz)
* psana2 idx mode
* psana1: add epix firmware id in epix id's for phil
* upgrade jupyterhub or use on-demand?
** one exe writing multiple files to improve performance
** xtcdata duplicate names throw
* move away from afs (mv pdsdata/psalg repo)
* spares
** make everything work with Debug instead of RelWithDebInfo (valerio, ric)
* move readout group config info from segment levels to ts
** optionally don't record selected detectors to disk
* fix camlink converter box with opal where only one strip works (requires camlink powercycle)
* daq window auto placement
* parallelized calibrations (mikhail)
* monitor deadtime per-lane (matt)
* move other hutches to lcls2
* MHz with real tmo analysis including pre/post processing partitioning (mona)
* create more platforms for procmgr, perhaps with offsets for each hutch based on xpm? (caf)
* parallel jupyterhub with visualization (copy euxfel?) (riccardo/mona/wilko/valerio)
* portable gpu detector corrections (kokkos/hip/openmp/opencl?)
* deploy releases everywhere, containers? (valerio) (nersc, sdf, new/old psana1)
* unified/integrated timetool calibration
* fix failing new-style psana1 tests (valerio)
* send multiple copy of events to shmem like lcls1
** small h5 ebeam/gasdet automatic storage (ro)
* meb (or later layer) broadcasts events to all clients (ami, python) (ric)
* update procServ (caf)
** syslog print throttling (caf)
* off-by-one support for low-rate devices
* units support in det xface
* put psana2 (and psana1?) on conda-forge
* in psana SRV callback only persist some fields to h5?
* once we have real data, work more on timetool calc in firmware
* scalable calib-fetch solution for shmem (have it for drp)
* sdf/nersc psana1 calib-dir sync (wilko)
* psana1: continuous integration of py3 (jenkins)
* lcls2 configdb tools: history, delete (into "trash" folder for recovery?) (ro)
* algorithms (drp/ana, e.g. beam-center finding)
* singularity at slac
* support more python versions
* fiber power readings from timing system kcu's (matt)
* timetool (ben): tag to front end, fiber power, toggle xpmini->lcls2 timing, clear readout

**********************************************************************

peppex cabling:
first cassette count from 1;
slot 2 hsd timing
slot 3 hsd leftmost
slot 4 hsd second from left

second cassette count from 1:
slot 4 hsd second from right
slot 5 hsd right
slot 6 opal

hsd timing plugged into xpm4 amc0 port 3 counting from 0

**********************************************************************

txi hxr kpp measurements: (aquila)
https://confluence.slac.stanford.edu/pages/viewpage.action?spaceKey=L2SI&title=RP+testing
- scheduled around halloween '23?
- 1kHz and 10kHz SC beam going through hxr undulators into txi
- wave8 daq (synced trigger)
- want 100Hz old hxr gasdet bld, gate width up to andy/philheimann
  o will do with unsynchronized epics.  silke says someone is working
    on this (called "GEM")
- NO ebeam bld (hxr bld (e.g. gasdet, some ebeam)  will be 120Hz?)
- epics
- no daq camera. use untimestamped controls camera, perhaps recorded in daq.
- need single mode fibers, may need cassettes
- timing in wave8 will be done earlier in tmo
- just wave8 and a bunch of epics variables
- other epics: power meter (andy, can get name from jyoti) controls uv sensitive diodes
  (alyssa, jyoti can provide epics names).  get gem-gdet names from silke (she
  said it might be working on may 11, 2023)

tickets:

https://jira.slac.stanford.edu/browse/LCLSECSD-1546
https://jira.slac.stanford.edu/browse/LCLSECSD-1874

**********************************************************************

lab3: 68.2F later: 66.8F
pietro's lab: 69.5F later: 69.5F
fee alcove outside racks: 71.3F
fee alcove inside rack: 81.4F

lab3 nodes:
drp-tst-dev008, dev004, acc05, acc02, acc01,
daq-tst-dev02 (add kcu?), dev03 (add kcu?), dev06 (hsd)

**********************************************************************

epixhremu timing link status

34: bad rxclock:  no fiber
37: looked good (linkup) -3.49
38: bad rxclock -3.69 (fixed by plugging/unplugging)
39: down: no fiber
40: rxclock 0: -26.22
41: bad rxclock: -3.9
42: bad rxclock: -3.6 (fixed by plugging/unplugging)

**********************************************************************

rix device issues:
piranha 71kHz and 100dt at 10kHz
mr2k1: no timing sub-window (just "no EVR" message)
hsd_0,1 (and dt with hsd2,3 eventually)
encoder
only chemrix wave8
manta not downstream of xpm?

recorded rixx1003721 run 169 with
71kHz: timing, wave8
10Hz: opal,manta
1Hz: vls,norm,dir

recorded rixx1003721 run 171 with
71kHz: timing, wave8, hsd_0, hsd_1
10Hz: opal,manta,vls,norm,dir,mr2k1(untimestamped),exsmanta

norm/dir rog 5, evtcode 272 (1Hz)
vls,opal,manta rog 6, evtcode 276 (10Hz, gated)
timing,wave8 rog 2, evtcode 284 (33kHz, gated)

c**********************************************************************

rix doesn't see problems at the moment. so maybe xpm0 is happy?

shortterm:

1. clean fibers and change transceivers between xpm0 and xpm2
2. separate xpm's in the atca crate
3. eject xpm2/xpm4 (should be no difference with fru_deactivate)
   (less likely since 6,4 go down) change transceivers
   (less likely since 6,4 go down) clean fibers
4. remove xpm2 (xpm0->xpm4->xpm6) (currently 6 is driven by 2)
5. swap xpm's with fee alcove
6. new version of software broke it? (unlikely since rix is working)
7. more RF isolation with air resistance modules
8. pyxpm software overwriting registers
9. only xpm's with front-panel inputs have trouble? (or "second tier leaf")

xpm4,5,6: noRTM
xpm0,2,3: RTM

longterm:

- reproduce in fee alcove (by unplugging fiber from ACR)
- instrument firmware
  o PLL input frequency drifting out of range (lock status)
  o power glitching
- is it a lingering temperature effect?  (maybe reproducible in the
  teststand)

possible partial solutions:
- reset state machine that gets stuck (we kludged a fix once with a loopback)
  Matt has an idea here.

timing issues:
- spares (including rtm's)
- txlinkreset (firmware)
- xpm link glitches (firmware)
- toggle between xpmmini/lcls2
- 25kHz fiducial
- xpm ports won't lock to themselves
- no link lock on timing KCUs
- distribute knowledge more widely
- general diagnostic techniques for understanding problems like the above (e.g. how do we know a PLL input is within a required frequency range?)
- want to try: synchronous retransmission (no clock domain crossing)
  o can be done without trying to understand firmware
- not just them telling us what to do: deeper committment
  o needs gert

**********************************************************************

yee preemption proposal:

only preemptable jobs: one "floating partition" called "shared"

have a floating partition for all facilities: "lcls", "suncat" is a facility
  - lcls float partition would be called lcls-float
  - suncat float partition would be called suncat-float
  - float partitions can have pre-emptable and non-preemptable jobs and higher priority jobs
  - floating partition: not locked down to specific hosts (can mix clusters)
  - the resources for the facility-float partition can be capped (only use 80%)

lcls real-time jobs would preempt jobs in "shared" partition first and
then other lower-priority lcls jobs

problem: lcls jobs are not preemptable

look into suspend-preemption again?

**********************************************************************

brainstorm with ric about epixm issues:

summary:
(1) we'll try to filter out [] () in dgram.cc
- can't translate square brackets to xtc2. leave them in configdb so yaml goes along for the ride, take them out 
- current method: remove square brackets in xtc, put in for rogue python, remove for xtc2
(2) "no detname" error from PythonConfigScanner.
(3) matt has educated us about how he handle the yaml files
